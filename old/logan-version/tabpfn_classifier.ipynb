{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84a3813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "# Standard Library Imports\n",
    "\n",
    "# TabPFN and Extensions\n",
    "\n",
    "try:\n",
    "    from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import (\n",
    "        AutoTabPFNClassifier,\n",
    "    )\n",
    "\n",
    "    from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Warning: Could not import TabPFN / TabPFN extensions. Please run installation above and restart the session afterwards (Runtime > Restart Session).\"\n",
    "    )\n",
    "\n",
    "# Data Science & Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Other ML Models\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "# Notebook UI/Display\n",
    "from IPython.display import Markdown, display\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.prompt import Prompt\n",
    "from rich.rule import Rule\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "# Scikit-Learn: Data & Preprocessing\n",
    "from sklearn.datasets import fetch_openml, load_breast_cancer\n",
    "\n",
    "# Scikit-Learn: Models\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# This transformer will be used to handle categorical features for the baseline models\n",
    "column_transformer = make_column_transformer(\n",
    "    (\n",
    "        OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "        make_column_selector(dtype_include=[\"object\", \"category\"]),\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92beab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Attempting client backend setup<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Attempting client backend setup\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Importing TabPFN client library<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Importing TabPFN client library\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Found existing access token, reusing it for authentication.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mFound existing access token, reusing it for authentication.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">âœ… TabPFN (client) initialized.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mâœ… TabPFN \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mclient\u001b[0m\u001b[1;32m)\u001b[0m\u001b[1;32m initialized.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console = Console()\n",
    "console.print(\"Attempting client backend setup...\")\n",
    "console.print(\"Importing TabPFN client library...\")\n",
    "from tabpfn_client import TabPFNClassifier, TabPFNRegressor, init\n",
    "\n",
    "init()\n",
    "console.print(\"[bold green]âœ… TabPFN (client) initialized.[/bold green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbda432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = [\n",
    "# Communication Services\n",
    "\"GOOGL\", \"GOOG\", \"T\", \"CHTR\", \"CMCSA\", \"EA\", \"FOXA\", \"FOX\", \"IPG\", \"LYV\", \"MTCH\", \"META\", \"NFLX\", \"NWSA\", \"NWS\", \"OMC\", \"PSKY\", \"TMUS\", \"TTWO\", \"TKO\", \"TTD\", \"VZ\", \"DIS\", \"WBD\",\n",
    "\n",
    "# consumer discretionary\n",
    "\"ABNB\", \"AMZN\", \"APTV\", \"AZO\", \"BBY\", \"BKNG\", \"CZR\", \"KMX\", \"CCL\", \"CMG\", \"DRI\", \"DECK\", \"DPZ\", \"DASH\", \"DHI\", \"EBAY\", \"EXPE\", \"F\", \"GRMN\", \"GM\", \"GPC\", \"HAS\", \"HLT\", \"HD\", \"LVS\", \"LEN\", \"LKQ\", \"LOW\", \"LULU\", \"MAR\", \"MCD\", \"MGM\", \"MHK\", \"NKE\", \"NCLH\", \"NVR\", \"ORLY\", \"POOL\", \"PHM\", \"RL\", \"ROST\", \"RCL\", \"SBUX\", \"TPR\", \"TSLA\", \"TJX\", \"TSCO\", \"ULTA\", \"WSM\", \"WYNN\", \"YUM\",\n",
    "\n",
    "# Consumer Staples\n",
    "\"MO\", \"ADM\", \"BF.B\", \"BG\", \"CPB\", \"CHD\", \"CLX\", \"KO\", \"CL\", \"CAG\", \"STZ\", \"COST\", \"DG\", \"DLTR\", \"EL\", \"GIS\", \"HSY\", \"HRL\", \"K\", \"KVUE\", \"KDP\", \"KMB\", \"KHC\", \"KR\", \"LW\", \"MKC\", \"TAP\", \"MDLZ\", \"MNST\", \"PEP\", \"PM\", \"PG\", \"SJM\", \"SYY\", \"TGT\", \"TSN\", \"WBA\", \"WMT\",\n",
    "\n",
    "# Energy\n",
    "\"APA\", \"BKR\", \"CVX\", \"COP\", \"CTRA\", \"DVN\", \"FANG\", \"EOG\", \"EQT\", \"EXE\", \"XOM\", \"HAL\", \"KMI\", \"MPC\", \"OXY\", \"OKE\", \"PSX\", \"SLB\", \"TRGP\", \"TPL\", \"VLO\", \"WMB\",\n",
    "\n",
    "# Financials\n",
    "\"AFL\", \"ALL\", \"AXP\", \"AIG\", \"AMP\", \"AON\", \"APO\", \"ACGL\", \"AJG\", \"AIZ\", \"BAC\", \"BRK.B\", \"BLK\", \"BX\", \"XYZ\", \"BK\", \"BRO\", \"COF\", \"CBOE\", \"SCHW\", \"CB\", \"CINF\", \"C\", \"CFG\", \"CME\", \"COIN\", \"CPAY\", \"ERIE\", \"EG\", \"FDS\", \"FIS\", \"FITB\", \"FI\", \"BEN\", \"GPN\", \"GL\", \"GS\", \"HIG\", \"HBAN\", \"ICE\", \"IVZ\", \"JKHY\", \"JPM\", \"KEY\", \"KKR\", \"L\", \"MTB\", \"MKTX\", \"MMC\", \"MA\", \"MET\", \"MCO\", \"MS\", \"MSCI\", \"NDAQ\", \"NTRS\", \"PYPL\", \"PNC\", \"PFG\", \"PGR\", \"PRU\", \"RJF\", \"RF\", \"SPGI\", \"STT\", \"SYF\", \"TROW\", \"TRV\", \"TFC\", \"USB\", \"V\", \"WRB\", \"WFC\", \"WTW\",\n",
    "\n",
    "# Healthcare\n",
    "\"ABT\", \"ABBV\", \"A\", \"ALGN\", \"AMGN\", \"BAX\", \"BDX\", \"TECH\", \"BIIB\", \"BSX\", \"BMY\", \"CAH\", \"COR\", \"CNC\", \"CRL\", \"CI\", \"COO\", \"CVS\", \"DHR\", \"DVA\", \"DXCM\", \"EW\", \"ELV\", \"GEHC\", \"GILD\", \"HCA\", \"HSIC\", \"HOLX\", \"HUM\", \"IDXX\", \"INCY\", \"PODD\", \"ISRG\", \"IQV\", \"JNJ\", \"LH\", \"LLY\", \"MCK\", \"MDT\", \"MRK\", \"MTD\", \"MRNA\", \"MOH\", \"PFE\", \"DGX\", \"REGN\", \"RMD\", \"RVTY\", \"SOLV\", \"STE\", \"SYK\", \"TMO\", \"UNH\", \"UHS\", \"VRTX\", \"VTRS\", \"WAT\", \"WST\", \"ZBH\", \"ZTS\",\n",
    "\n",
    "# Industrials\n",
    "\"MMM\", \"AOS\", \"ALLE\", \"AME\", \"ADP\", \"AXON\", \"BA\", \"BR\", \"BLDR\", \"CHRW\", \"CARR\", \"CAT\", \"CTAS\", \"CPRT\", \"CSX\", \"CMI\", \"DAY\", \"DE\", \"DAL\", \"DOV\", \"ETN\", \"EMR\", \"EFX\", \"EXPD\", \"FAST\", \"FDX\", \"FTV\", \"GE\", \"GEV\", \"GNRC\", \"GD\", \"HON\", \"HWM\", \"HUBB\", \"HII\", \"IEX\", \"ITW\", \"IR\", \"JBHT\", \"J\", \"JCI\", \"LHX\", \"LDOS\", \"LII\", \"LMT\", \"MAS\", \"NDSN\", \"NSC\", \"NOC\", \"ODFL\", \"OTIS\", \"PCAR\", \"PH\", \"PAYX\", \"PAYC\", \"PNR\", \"PWR\", \"RTX\", \"RSG\", \"ROK\", \"ROL\", \"SNA\", \"LUV\", \"SWK\", \"TXT\", \"TT\", \"TDG\", \"UBER\", \"UNP\", \"UAL\", \"UPS\", \"URI\", \"VLTO\", \"VRSK\", \"GWW\", \"WAB\", \"WM\", \"XYL\",\n",
    "\n",
    "# Information Technology\n",
    "\"ACN\", \"ADBE\", \"AMD\", \"AKAM\", \"APH\", \"ADI\", \"AAPL\", \"AMAT\", \"ANET\", \"ADSK\", \"AVGO\", \"CDNS\", \"CDW\", \"CSCO\", \"CTSH\", \"GLW\", \"CRWD\", \"DDOG\", \"DELL\", \"ENPH\", \"EPAM\", \"FFIV\", \"FICO\", \"FSLR\", \"FTNT\", \"IT\", \"GEN\", \"GDDY\", \"HPE\", \"HPQ\", \"IBM\", \"INTC\", \"INTU\", \"JBL\", \"KEYS\", \"KLAC\", \"LRCX\", \"MCHP\", \"MU\", \"MSFT\", \"MPWR\", \"MSI\", \"NTAP\", \"NVDA\", \"NXPI\", \"ON\", \"ORCL\", \"PLTR\", \"PANW\", \"PTC\", \"QCOM\", \"ROP\", \"CRM\", \"STX\", \"NOW\", \"SWKS\", \"SMCI\", \"SNPS\", \"TEL\", \"TDY\", \"TER\", \"TXN\", \"TRMB\", \"TYL\", \"VRSN\", \"WDC\", \"WDAY\", \"ZBRA\",\n",
    "\n",
    "# Materials\n",
    "\"APD\", \"ALB\", \"AMCR\", \"AVY\", \"BALL\", \"CF\", \"CTVA\", \"DOW\", \"DD\", \"EMN\", \"ECL\", \"FCX\", \"IFF\", \"IP\", \"LIN\", \"LYB\", \"MLM\", \"MOS\", \"NEM\", \"NUE\", \"PKG\", \"PPG\", \"SHW\", \"SW\", \"STLD\", \"VMC\",\n",
    "\n",
    "# Real Estate\n",
    "\"ARE\", \"AMT\", \"AVB\", \"BXP\", \"CPT\", \"CBRE\", \"CSGP\", \"CCI\", \"DLR\", \"EQIX\", \"EQR\", \"ESS\", \"EXR\", \"FRT\", \"DOC\", \"HST\", \"INVH\", \"IRM\", \"KIM\", \"MAA\", \"PLD\", \"PSA\", \"O\", \"REG\", \"SBAC\", \"SPG\", \"UDR\", \"VTR\", \"VICI\", \"WELL\", \"WY\",\n",
    "\n",
    "# Utilities\n",
    "\"AES\", \"LNT\", \"AEE\", \"AEP\", \"AWK\", \"ATO\", \"CNP\", \"CMS\", \"ED\", \"CEG\", \"D\", \"DTE\", \"DUK\", \"EIX\", \"ETR\", \"EVRG\", \"ES\", \"EXC\", \"FE\", \"NEE\", \"NI\", \"NRG\", \"PCG\", \"PNW\", \"PPL\", \"PEG\", \"SRE\", \"SO\", \"VST\", \"WEC\", \"XEL\"\n",
    "]\n",
    "\n",
    "\n",
    "start = \"1990-01-01\"\n",
    "#end = \"1991-01-01\"\n",
    "end = \"2015-12-31\"\n",
    "time_args = [start,end]\n",
    "prediction_type = \"classification\"\n",
    "use_nlp = True\n",
    "nlp_method = \"aggregated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a697b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training dataset (.npz):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training dataset (.npz): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.02it/s]\n",
      "Loading validation dataset (.npz): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 16.58it/s]\n",
      "Loading test dataset (.npz): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  9.84it/s]\n",
      "Loading metrics dataset (.npz): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 408.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check cache first with full stock list\n",
    "input_data = util.load_data_from_cache(stocks, time_args, data_dir=\"data\", prediction_type=prediction_type, use_nlp=use_nlp, nlp_method=nlp_method)\n",
    "\n",
    "if input_data is None:\n",
    "    # Step 2: Load saved problematic stocks for this time period\n",
    "    problematic_stocks_saved = util._load_problematic_stocks(time_args, data_dir=\"data\")\n",
    "    \n",
    "    # Step 3: Remove problematic stocks from input set\n",
    "    if problematic_stocks_saved:\n",
    "        valid_stocks = [stock for stock in stocks if stock not in problematic_stocks_saved]\n",
    "        print(f\"[data] Loaded {len(problematic_stocks_saved)} previously identified problematic stocks for this time period\")\n",
    "        print(f\"[data] Filtered input: {len(stocks)} -> {len(valid_stocks)} stocks\")\n",
    "    else:\n",
    "        valid_stocks = stocks\n",
    "    \n",
    "    if len(valid_stocks) == 0:\n",
    "        raise RuntimeError(\"No valid stocks found after filtering problematic stocks.\")\n",
    "    \n",
    "    # Step 4: Check cache with filtered stocks\n",
    "    input_data = util.load_data_from_cache(valid_stocks, time_args, data_dir=\"data\", prediction_type=prediction_type, use_nlp=use_nlp, nlp_method=nlp_method)\n",
    "    \n",
    "    if input_data is None:\n",
    "        # Step 5: Download data (will save problematic stocks for future runs)\n",
    "        print(\"[data] Cache not found, downloading data...\")\n",
    "        open_close, failed_stocks_dict = util.handle_yfinance_errors(valid_stocks, time_args, max_retries=1)\n",
    "        \n",
    "        if open_close is None:\n",
    "            raise RuntimeError(\"ERROR: Failed to download any stock data. Cannot proceed.\")\n",
    "        \n",
    "        # Calculate problematic stocks from this download (new problematic stocks found in valid_stocks)\n",
    "        new_problematic = [stock for stock in valid_stocks if stock not in open_close[\"Open\"].columns]\n",
    "        # Combine with previously known problematic stocks\n",
    "        all_problematic = list(problematic_stocks_saved) + new_problematic if problematic_stocks_saved else new_problematic\n",
    "        \n",
    "        # Step 6: Process and save data (get_data will save problematic stocks)\n",
    "        print(\"[data] Processing downloaded data and saving to cache...\")\n",
    "        input_data = util.get_data(valid_stocks, time_args, data_dir=\"data\", prediction_type=prediction_type, open_close_data=open_close, problematic_stocks=all_problematic if all_problematic else None, use_nlp=use_nlp, nlp_method=nlp_method)\n",
    "        if isinstance(input_data, int):\n",
    "            raise RuntimeError(\"Error getting data from util.get_data()\")\n",
    "    else:\n",
    "        print(\"[data] Found cache for filtered stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a4d649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46788e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(input_data) == 10:\n",
    "    X_train, X_val, X_test, Y_train, Y_val, Y_test, D_train, D_val, D_test, Rev_test = input_data\n",
    "    Returns_test = None  # Old format doesn't have Returns\n",
    "    Sp500_test = None  # Old format doesn't have S&P 500\n",
    "elif len(input_data) == 11:\n",
    "    X_train, X_val, X_test, Y_train, Y_val, Y_test, D_train, D_val, D_test, Rev_test, Sp500_test = input_data\n",
    "    Returns_test = None  # Format doesn't have Returns\n",
    "elif len(input_data) == 12:\n",
    "    X_train, X_val, X_test, Y_train, Y_val, Y_test, D_train, D_val, D_test, Rev_test, Returns_test, Sp500_test = input_data\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected number of elements in input_data: {len(input_data)}. Expected 10, 11, or 12 elements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b704b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1445936, 31, 13])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0253acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00549649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1445936, 403])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c30531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1445936\n",
      "Chunk size: 50000\n",
      "Number of chunks: 29\n",
      "\n",
      "Fitting model on 1000 samples...\n",
      "âœ… Model fitted successfully!\n",
      "\n",
      "Model has 'executor_' attribute: False\n",
      "âš ï¸  save_fitted_tabpfn_model failed: Model doesn't have executor_ attribute\n",
      "Trying alternative: saving with pickle...\n",
      "ðŸ’¾ Saved fitted model using pickle to 'my_fitted_tabpfn_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tabpfn import save_fitted_tabpfn_model\n",
    "\n",
    "# TabPFN has a limit of 50,000 rows\n",
    "CHUNK_SIZE = 50000\n",
    "\n",
    "# Convert to numpy if it's a torch tensor\n",
    "if isinstance(X_train, torch.Tensor):\n",
    "    X_train_np = X_train.numpy()\n",
    "    Y_train_np = Y_train.numpy()\n",
    "else:\n",
    "    X_train_np = X_train\n",
    "    Y_train_np = Y_train\n",
    "\n",
    "# Flatten Y_train to 1D array (fixes the warning)\n",
    "if Y_train_np.ndim > 1:\n",
    "    Y_train_np = Y_train_np.ravel()\n",
    "\n",
    "# Get total number of samples\n",
    "total_samples = X_train_np.shape[0]\n",
    "num_chunks = int(np.ceil(total_samples / CHUNK_SIZE))\n",
    "\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Chunk size: {CHUNK_SIZE}\")\n",
    "print(f\"Number of chunks: {num_chunks}\")\n",
    "\n",
    "# IMPORTANT: TabPFN doesn't support incremental fitting!\n",
    "# Each fit() call replaces the previous state, so we can only use ONE chunk.\n",
    "# Option 1: Use the last chunk (most recent data)\n",
    "# Option 2: Use a random sample\n",
    "# Option 3: Use the first chunk\n",
    "\n",
    "\n",
    "\n",
    "X_chunk = X_train_np[:1000]\n",
    "Y_chunk = Y_train_np[:1000]\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = TabPFNClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the selected chunk\n",
    "print(f\"\\nFitting model on {len(X_chunk)} samples...\")\n",
    "model = model.fit(X_chunk, Y_chunk)\n",
    "print(\"âœ… Model fitted successfully!\")\n",
    "\n",
    "# Check if model has executor_ attribute (required for save_fitted_tabpfn_model)\n",
    "has_executor = hasattr(model, 'executor_')\n",
    "print(f\"\\nModel has 'executor_' attribute: {has_executor}\")\n",
    "\n",
    "# Try to save using save_fitted_tabpfn_model first\n",
    "model_path = \"my_fitted_tabpfn_model.pkl\"\n",
    "try:\n",
    "    if has_executor:\n",
    "        save_fitted_tabpfn_model(model, model_path)\n",
    "        print(f\"ðŸ’¾ Saved fitted model using save_fitted_tabpfn_model to '{model_path}'\")\n",
    "    else:\n",
    "        raise AttributeError(\"Model doesn't have executor_ attribute\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  save_fitted_tabpfn_model failed: {e}\")\n",
    "    print(\"Trying alternative: saving with pickle...\")\n",
    "    # Fallback to pickle\n",
    "    try:\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"ðŸ’¾ Saved fitted model using pickle to '{model_path}'\")\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ Pickle save also failed: {e2}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0aefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1445936\n",
      "Chunk size: 50000\n",
      "Number of chunks: 29\n",
      "\n",
      "Processing chunk 1/29 (rows 0 to 49999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 1/29\n",
      "\n",
      "Processing chunk 2/29 (rows 50000 to 99999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 2/29\n",
      "\n",
      "Processing chunk 3/29 (rows 100000 to 149999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 3/29\n",
      "\n",
      "Processing chunk 4/29 (rows 150000 to 199999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 4/29\n",
      "\n",
      "Processing chunk 5/29 (rows 200000 to 249999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 5/29\n",
      "\n",
      "Processing chunk 6/29 (rows 250000 to 299999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 6/29\n",
      "\n",
      "Processing chunk 7/29 (rows 300000 to 349999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 7/29\n",
      "\n",
      "Processing chunk 8/29 (rows 350000 to 399999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 8/29\n",
      "\n",
      "Processing chunk 9/29 (rows 400000 to 449999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 9/29\n",
      "\n",
      "Processing chunk 10/29 (rows 450000 to 499999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 10/29\n",
      "\n",
      "Processing chunk 11/29 (rows 500000 to 549999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 11/29\n",
      "\n",
      "Processing chunk 12/29 (rows 550000 to 599999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 12/29\n",
      "\n",
      "Processing chunk 13/29 (rows 600000 to 649999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 13/29\n",
      "\n",
      "Processing chunk 14/29 (rows 650000 to 699999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 14/29\n",
      "\n",
      "Processing chunk 15/29 (rows 700000 to 749999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 15/29\n",
      "\n",
      "Processing chunk 16/29 (rows 750000 to 799999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 16/29\n",
      "\n",
      "Processing chunk 17/29 (rows 800000 to 849999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 17/29\n",
      "\n",
      "Processing chunk 18/29 (rows 850000 to 899999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 18/29\n",
      "\n",
      "Processing chunk 19/29 (rows 900000 to 949999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 19/29\n",
      "\n",
      "Processing chunk 20/29 (rows 950000 to 999999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 20/29\n",
      "\n",
      "Processing chunk 21/29 (rows 1000000 to 1049999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 21/29\n",
      "\n",
      "Processing chunk 22/29 (rows 1050000 to 1099999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 22/29\n",
      "\n",
      "Processing chunk 23/29 (rows 1100000 to 1149999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 23/29\n",
      "\n",
      "Processing chunk 24/29 (rows 1150000 to 1199999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 24/29\n",
      "\n",
      "Processing chunk 25/29 (rows 1200000 to 1249999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 25/29\n",
      "\n",
      "Processing chunk 26/29 (rows 1250000 to 1299999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 26/29\n",
      "\n",
      "Processing chunk 27/29 (rows 1300000 to 1349999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 27/29\n",
      "\n",
      "Processing chunk 28/29 (rows 1350000 to 1399999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 28/29\n",
      "\n",
      "Processing chunk 29/29 (rows 1400000 to 1445935)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganyamamoto/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed chunk 29/29\n",
      "\n",
      "ðŸŽ‰ Finished fitting model on all 29 chunks!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Estimator must be fitted before saving.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸŽ‰ Finished fitting model on all \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Save the final fitted model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43msave_fitted_tabpfn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy_fitted_tabpfn_model.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ’¾ Saved fitted model to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmy_fitted_tabpfn_model.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn/model_loading.py:893\u001b[39m, in \u001b[36msave_fitted_tabpfn_model\u001b[39m\u001b[34m(estimator, path)\u001b[39m\n\u001b[32m    887\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Persist a fitted TabPFN estimator to ``path``.\u001b[39;00m\n\u001b[32m    888\u001b[39m \n\u001b[32m    889\u001b[39m \u001b[33;03mThis stores the initialization parameters and the fitted state, but crucially\u001b[39;00m\n\u001b[32m    890\u001b[39m \u001b[33;03momits the large foundation model weights for efficiency.\u001b[39;00m\n\u001b[32m    891\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33mexecutor_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m893\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mEstimator must be fitted before saving.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    895\u001b[39m path = Path(path)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path.suffix != \u001b[33m\"\u001b[39m\u001b[33m.tabpfn_fit\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: Estimator must be fitted before saving."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tabpfn import save_fitted_tabpfn_model\n",
    "\n",
    "# TabPFN has a limit of 50,000 rows\n",
    "CHUNK_SIZE = 50000\n",
    "\n",
    "# Convert to numpy if it's a torch tensor\n",
    "if isinstance(X_train, torch.Tensor):\n",
    "    X_train_np = X_train.numpy()\n",
    "    Y_train_np = Y_train.numpy()\n",
    "else:\n",
    "    X_train_np = X_train\n",
    "    Y_train_np = Y_train\n",
    "\n",
    "# Flatten Y_train to 1D array (fixes the warning)\n",
    "if Y_train_np.ndim > 1:\n",
    "    Y_train_np = Y_train_np.ravel()\n",
    "\n",
    "# Get total number of samples\n",
    "total_samples = X_train_np.shape[0]\n",
    "num_chunks = int(np.ceil(total_samples / CHUNK_SIZE))\n",
    "\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Chunk size: {CHUNK_SIZE}\")\n",
    "print(f\"Number of chunks: {num_chunks}\")\n",
    "\n",
    "# IMPORTANT: TabPFN doesn't support incremental fitting!\n",
    "# Each fit() call replaces the previous state, so we can only use ONE chunk.\n",
    "# Option 1: Use the last chunk (most recent data)\n",
    "# Option 2: Use a random sample\n",
    "# Option 3: Use the first chunk\n",
    "\n",
    "# Using the last chunk (most recent data)\n",
    "use_last_chunk = True\n",
    "if use_last_chunk:\n",
    "    start_idx = max(0, total_samples - CHUNK_SIZE)\n",
    "    end_idx = total_samples\n",
    "    X_chunk = X_train_np[start_idx:end_idx]\n",
    "    Y_chunk = Y_train_np[start_idx:end_idx]\n",
    "    print(f\"\\nUsing last chunk: rows {start_idx} to {end_idx-1} ({len(X_chunk)} samples)\")\n",
    "else:\n",
    "    # Use first chunk\n",
    "    X_chunk = X_train_np[0:min(CHUNK_SIZE, total_samples)]\n",
    "    Y_chunk = Y_train_np[0:min(CHUNK_SIZE, total_samples)]\n",
    "    print(f\"\\nUsing first chunk: rows 0 to {len(X_chunk)-1} ({len(X_chunk)} samples)\")\n",
    "\n",
    "# Initialize the model\n",
    "model = TabPFNClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the selected chunk\n",
    "print(f\"\\nFitting model on {len(X_chunk)} samples...\")\n",
    "model.fit(X_chunk, Y_chunk)\n",
    "print(\"âœ… Model fitted successfully!\")\n",
    "\n",
    "# Check if model has executor_ attribute (required for save_fitted_tabpfn_model)\n",
    "has_executor = hasattr(model, 'executor_')\n",
    "print(f\"\\nModel has 'executor_' attribute: {has_executor}\")\n",
    "\n",
    "# Try to save using save_fitted_tabpfn_model first\n",
    "model_path = \"my_fitted_tabpfn_model.pkl\"\n",
    "try:\n",
    "    if has_executor:\n",
    "        save_fitted_tabpfn_model(model, model_path)\n",
    "        print(f\"ðŸ’¾ Saved fitted model using save_fitted_tabpfn_model to '{model_path}'\")\n",
    "    else:\n",
    "        raise AttributeError(\"Model doesn't have executor_ attribute\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  save_fitted_tabpfn_model failed: {e}\")\n",
    "    print(\"Trying alternative: saving with pickle...\")\n",
    "    # Fallback to pickle\n",
    "    try:\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"ðŸ’¾ Saved fitted model using pickle to '{model_path}'\")\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ Pickle save also failed: {e2}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82c281c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_fitted_tabpfn_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save the final fitted model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msave_fitted_tabpfn_model\u001b[49m(model, \u001b[33m\"\u001b[39m\u001b[33mmy_fitted_tabpfn_model.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ’¾ Saved fitted model to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmy_fitted_tabpfn_model.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'save_fitted_tabpfn_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the final fitted model\n",
    "save_fitted_tabpfn_model(model, \"my_fitted_tabpfn_model.pkl\")\n",
    "print(\"ðŸ’¾ Saved fitted model to 'my_fitted_tabpfn_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733780f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of rows cannot be more than 50000.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model = TabPFNClassifier(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Save the fitted model\u001b[39;00m\n\u001b[32m      5\u001b[39m save_fitted_tabpfn_model(model, \u001b[33m\"\u001b[39m\u001b[33mmy_fitted_tabpfn_model.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:201\u001b[39m, in \u001b[36mTabPFNClassifier.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[32m    198\u001b[39m     \u001b[38;5;66;03m# assert init() is called\u001b[39;00m\n\u001b[32m    199\u001b[39m     init()\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[43mvalidate_data_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     X = _clean_text_features(X)\n\u001b[32m    203\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_targets_and_classes(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/class/CSCI/566/project/StockPredictor/.venv/lib/python3.11/site-packages/tabpfn_client/estimator.py:500\u001b[39m, in \u001b[36mvalidate_data_size\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# length and feature assertions\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.shape[\u001b[32m0\u001b[39m] > MAX_ROWS:\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe number of rows cannot be more than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_ROWS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.shape[\u001b[32m1\u001b[39m] > MAX_COLS:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe number of columns cannot be more than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_COLS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: The number of rows cannot be more than 50000."
     ]
    }
   ],
   "source": [
    "# Later, load the fitted model\n",
    "import pickle\n",
    "from tabpfn import load_fitted_tabpfn_model\n",
    "\n",
    "model_path = \"my_fitted_tabpfn_model.pkl\"\n",
    "\n",
    "try:\n",
    "    # Try loading with load_fitted_tabpfn_model first\n",
    "    loaded_model = load_fitted_tabpfn_model(model_path)\n",
    "    print(\"âœ… Loaded model using load_fitted_tabpfn_model\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  load_fitted_tabpfn_model failed: {e}\")\n",
    "    print(\"Trying alternative: loading with pickle...\")\n",
    "    # Fallback to pickle\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "        print(\"âœ… Loaded model using pickle\")\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ Pickle load also failed: {e2}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa87555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the model with pickle and make a prediction\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "model_path = \"my_fitted_tabpfn_model.pkl\"\n",
    "\n",
    "# Load model using pickle\n",
    "print(\"Loading model with pickle...\")\n",
    "try:\n",
    "    with open(model_path, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    print(\"âœ… Successfully loaded model with pickle!\")\n",
    "    \n",
    "    # Verify the model is usable by checking its type\n",
    "    print(f\"Model type: {type(loaded_model)}\")\n",
    "    print(f\"Model has 'predict' method: {hasattr(loaded_model, 'predict')}\")\n",
    "    \n",
    "    # Optional: Test prediction on a small sample\n",
    "    # Note: This requires X_test or X_val to be available\n",
    "    if 'X_test' in globals() or 'X_val' in globals():\n",
    "        test_X = X_val[:10] if 'X_val' in globals() else X_test[:10]\n",
    "        if isinstance(test_X, torch.Tensor):\n",
    "            test_X = test_X.numpy()\n",
    "        if test_X.ndim > 2:\n",
    "            test_X = test_X.reshape(test_X.shape[0], -1)\n",
    "        \n",
    "        print(f\"\\nTesting prediction on {len(test_X)} samples...\")\n",
    "        predictions = loaded_model.predict(test_X)\n",
    "        print(f\"âœ… Predictions shape: {predictions.shape}\")\n",
    "        print(f\"Sample predictions: {predictions[:5]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to load model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d894e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
